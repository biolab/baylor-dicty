{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OvR logistic regression with weights adjusted based on weights of other phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'stages_DE.OvR' from '/home/khrovatin/git/baylor-dicty/stages_DE/OvR.py'>"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from importlib import reload\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0,module_path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support,roc_auc_score\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "import sklearn.preprocessing as pp\n",
    "#alt.renderers.enable('notebook')\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "import stages_DE.stages_library\n",
    "import importlib\n",
    "importlib.reload(stages_DE.stages_library)\n",
    "\n",
    "from networks.functionsDENet import loadPickle,savePickle\n",
    "from stages_DE.stages_library import PHENOTYPES, PHENOTYPES_X, summary_classification, summary_classification_print_sort, scatter_catgory\n",
    "import stages_DE.OvR as OvR\n",
    "importlib.reload(OvR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteus=True\n",
    "if proteus:\n",
    "    pathClassification = '/home/khrovatin/timeTrajectoriesNet/data/stages/classification/'\n",
    "    dataPath= '/home/khrovatin/timeTrajectoriesNet/data/RPKUM/'\n",
    "else:\n",
    "    pathClassification = '/home/karin/Documents/timeTrajectories/data/stages/classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = pd.read_csv(dataPath + 'mergedGenes_RPKUM.tsv', sep='\\t', index_col=0)\n",
    "conditions = pd.read_csv(dataPath + 'conditions_mergedGenes.tsv', sep='\\t', index_col=None)\n",
    "\n",
    "# Retain only samples with annotations\n",
    "Y = conditions[(conditions[PHENOTYPES] != 0).any(axis=1)]\n",
    "X = genes[Y.Measurment].T.values\n",
    "#Y = conditions.query('Group ==\"WT\"')[(conditions.query('Group ==\"WT\"')[PHENOTYPES] != 0).any(axis=1)]\n",
    "#X = genes[Y.Measurment].T.values\n",
    "\n",
    "# Remove targets with too little positive samples\n",
    "order=['no_agg','disappear', 'stream', 'lag', 'tag', 'tip', 'slug', 'mhat', 'cul', 'FB']\n",
    "#order=['no_agg', 'stream', 'lag', 'tag',  'slug', 'mhat', 'cul', 'FB']\n",
    "Y = Y[order].values\n",
    "\n",
    "# Remove constant features\n",
    "X=X[:,(X.std(axis=0)!=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in train and test as was done for 5-fold cross validation, but using only 1 fold for now\n",
    "X_train, Y_train, X_test, Y_test = iterative_train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale X features to [0,1], use X_train scaller to also scale X_test\n",
    "scaler = pp.MinMaxScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train unmodified OvR for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Re)setting estimators\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight='balanced',\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto', n_jobs=20,\n",
       "                                                 penalty='none',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='saga', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "                    n_jobs=10, warm_start=False)"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = OvR.OneVsRestClassifier(estimator=LogisticRegression(n_jobs=20,  solver='saga',penalty='none',\n",
    "                                            class_weight='balanced'\n",
    "                                            #,warm_start=True,max_iter=1\n",
    "                                             ), n_jobs=Y_train.shape[1])\n",
    "classifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train modified weights model - adjust weights based on weights for other phenotypes. Train sub-models so that in the middle of the training the weights are adjusted after each itteration based on weight of other sub-models/phenotypes. Currently this finds largest region of positive weights (across targets/phenotypes, according to weight sum) for each gene and then downvotes (divides) any positive weiths (of other phenotypes) that are outside of this region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Re)setting estimators\n"
     ]
    }
   ],
   "source": [
    "classifier_ordered = OvR.OneVsRestClassifier(estimator=LogisticRegression(n_jobs=20,  solver='saga',penalty='none',\n",
    "                                            class_weight='balanced'\n",
    "                                            ,warm_start=True,max_iter=1\n",
    "                                             ), n_jobs=Y_train.shape[1],warm_start=True)\n",
    "\n",
    "max=100\n",
    "for i in range(max):\n",
    "    classifier_ordered.fit(X_train,Y_train)\n",
    "    if 5 < i < max-5:\n",
    "        for feature_idx in range(X_train.shape[1]):\n",
    "            start=0\n",
    "            end=0\n",
    "            peaks=[]\n",
    "            running=False\n",
    "            curr_peak=0\n",
    "            positive_coefs=[]\n",
    "            for target_idx in range(Y_train.shape[1]):\n",
    "                coef=classifier_ordered.estimators_[target_idx].coef_[0][feature_idx]\n",
    "                if coef > 0:\n",
    "                    positive_coefs.append(target_idx)\n",
    "                    if not running:\n",
    "                        running=True\n",
    "                        start=target_idx\n",
    "                    end=target_idx\n",
    "                    curr_peak+=coef\n",
    "                elif coef < 0 and running:\n",
    "                    running=False\n",
    "                    peaks.append((start,end,curr_peak))\n",
    "            if len(peaks)>0:\n",
    "                best_peak = sorted(peaks, key=lambda tup: tup[2])[-1]\n",
    "                modify_down=[idx for idx in positive_coefs if idx < best_peak[0] or idx > best_peak[1]]\n",
    "                for modify_idx in modify_down:\n",
    "                    coef=classifier_ordered.estimators_[modify_idx].coef_[0][feature_idx]\n",
    "                    classifier_ordered.estimators_[modify_idx].coef_[0][feature_idx]=coef/2\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare weights of individual genes in both models\n",
    "c=classifier_ordered\n",
    "plt.hlines(0,0,len(c.estimators_)-1)\n",
    "# Find a gene with high weight for a target in modified model\n",
    "for i in range(X.shape[1]):\n",
    "#for i in [1000]:\n",
    "    if c.estimators_[2].coef_[0][i]>0.01:\n",
    "        #Plot weights of both models\n",
    "        for e in range(len(c.estimators_)):\n",
    "            plt.scatter(e,c.estimators_[e].coef_[0][i],c='b',alpha=0.5)\n",
    "            plt.scatter(e,classifier.estimators_[e].coef_[0][i],c='r',alpha=0.5)\n",
    "        print(i,genes[genes.std(axis=1)!=0].index[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmodified model\n",
      "   precision  recall  F_score  support      Group\n",
      "0       0.90    0.84     0.87     31.0     no_agg\n",
      "1       0.33    0.25     0.29      4.0  disappear\n",
      "2       0.70    0.64     0.67     11.0     stream\n",
      "3       0.72    0.76     0.74     17.0        lag\n",
      "4       0.82    0.69     0.75     13.0        tag\n",
      "5       0.50    0.20     0.29      5.0        tip\n",
      "6       0.89    0.73     0.80     11.0       slug\n",
      "7       0.50    1.00     0.67      3.0       mhat\n",
      "8       0.75    1.00     0.86      6.0        cul\n",
      "9       1.00    0.80     0.89      5.0         FB\n",
      "\n",
      "Modified weights model\n",
      "   precision  recall  F_score  support      Group\n",
      "0       0.85    0.90     0.88     31.0     no_agg\n",
      "1       0.22    1.00     0.36      4.0  disappear\n",
      "2       0.34    1.00     0.51     11.0     stream\n",
      "3       0.70    0.41     0.52     17.0        lag\n",
      "4       0.41    0.92     0.57     13.0        tag\n",
      "5       0.50    0.20     0.29      5.0        tip\n",
      "6       0.32    1.00     0.49     11.0       slug\n",
      "7       0.23    1.00     0.38      3.0       mhat\n",
      "8       0.40    1.00     0.57      6.0        cul\n",
      "9       0.25    0.80     0.38      5.0         FB\n"
     ]
    }
   ],
   "source": [
    "print('Unmodified model')\n",
    "Y_predicted=classifier.predict(X_test)\n",
    "prfs=pd.DataFrame(precision_recall_fscore_support(Y_test, Y_predicted),index=['precision','recall','F_score','support']).T\n",
    "prfs['Group']=order\n",
    "print(prfs.round(2))\n",
    "print('\\nModified weights model')\n",
    "Y_predicted=classifier_ordered.predict(X_test)\n",
    "prfs=pd.DataFrame(precision_recall_fscore_support(Y_test, Y_predicted),index=['precision','recall','F_score','support']).T\n",
    "prfs['Group']=order\n",
    "print(prfs.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance of falsely predicted labels to true labels\n",
    "For each sample that has at least some labels calculate the distance to the closest true label of FP and closest TP of FN. Average this over all FP/FN. It would be desired that: 1.) FP would be close to the real label (low FP distance). 2.) FN would be away from the closest TP (high FN distance) - The only FN would be those that are not likely based on the TP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_error(Y_test,Y_predicted):\n",
    "    wrong_total=0\n",
    "    n_wrong=0\n",
    "    missing_total=0\n",
    "    n_missing=0\n",
    "    order_arr=np.array(order)\n",
    "    for row_idx in range(Y_test.shape[0]):\n",
    "        y_test=Y_test[row_idx,:]\n",
    "        # Use only samples with at least some ground truth positive labels and some wrongly predicted\n",
    "        if y_test.sum()>0:\n",
    "            y_predicted=Y_predicted[row_idx,:]\n",
    "            if (y_predicted!=y_test).any():\n",
    "                #print('***********')\n",
    "                #print(y_test.astype('int'))\n",
    "                #print(y_predicted)\n",
    "                # Which phenotypes were predicted/are in fact present\n",
    "                targets=order_arr[y_test==1]\n",
    "                predicted_targets=order_arr[y_predicted==1]\n",
    "                true_x=[PHENOTYPES_X[phenotype] for phenotype in targets]\n",
    "                predicted_x=[PHENOTYPES_X[phenotype] for phenotype in predicted_targets]\n",
    "                # Find closest actuall lable to the FP\n",
    "                for x in predicted_x:\n",
    "                    if x not in true_x:\n",
    "                        n_wrong+=1\n",
    "                        min_diff=np.inf\n",
    "                        for x_true in true_x:\n",
    "                            diff=abs(x-x_true)\n",
    "                            if diff<min_diff:\n",
    "                                min_diff=diff\n",
    "                        wrong_total+=min_diff\n",
    "                # Find closest TP label to the FN\n",
    "                for x in true_x:\n",
    "                    if x not in predicted_x and len(predicted_x)>0:\n",
    "                        n_missing+=1\n",
    "                        min_diff=np.inf\n",
    "                        for x_predicted in predicted_x:\n",
    "                            diff=abs(x-x_predicted)\n",
    "                            if diff<min_diff:\n",
    "                                min_diff=diff\n",
    "                        missing_total+=min_diff\n",
    "\n",
    "    print('Average distance of missing annotations (FN) to the closest TP one:',round(missing_total/n_missing,2))     \n",
    "    print('Average distance of wrong annotations (FP) to the closest true one:',round(wrong_total/n_wrong,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmodified model:\n",
      "Average distance of missing annotations (FN) to the closest TP one: 1.89\n",
      "Average distance of wrong annotations (FP) to the closest true one: 1.55\n",
      "\n",
      "Modified weights model:\n",
      "Average distance of missing annotations (FN) to the closest TP one: 1.58\n",
      "Average distance of wrong annotations (FP) to the closest true one: 1.97\n"
     ]
    }
   ],
   "source": [
    "print('Unmodified model:')\n",
    "Y_predicted=classifier.predict(X_test)\n",
    "distance_error(Y_test,Y_predicted)\n",
    "print('\\nModified weights model:')\n",
    "Y_predicted=classifier_ordered.predict(X_test)\n",
    "distance_error(Y_test,Y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The algorithm, as currently implemented, performs worse than unmodified model - both based on OvR F score and distance of false predictions to the truth. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constrain weights to positive\n",
    "Use R glmnet package for logistic regression, as it can constrain weights to be above 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "from rpy2 import  robjects\n",
    "from rpy2.robjects import pandas2ri \n",
    "from rpy2.rinterface_lib.embedded import RRuntimeError\n",
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = importr('base')\n",
    "utils = importr('utils')\n",
    "glmnet=importr('glmnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "  |======================================================================| 100%\n",
      "1\n",
      "  |======================================================================| 100%\n",
      "2\n",
      "  |======================================================================| 100%\n",
      "3\n",
      "  |======================================================================| 100%\n",
      "4\n",
      "  |======================================================================| 100%\n",
      "5\n",
      "  |======================================================================| 100%\n",
      "6\n",
      "  |======================================================================| 100%\n",
      "7\n",
      "  |======================================================================| 100%\n",
      "8\n",
      "  |======================================================================| 100%\n",
      "9\n",
      "  |======================================================================| 100%\n"
     ]
    }
   ],
   "source": [
    "Y_predicted=[]\n",
    "N_features=[]\n",
    "for target_idx in range(Y.shape[1]):\n",
    "    print(target_idx)\n",
    "    #Sample weights as in sklearn models\n",
    "    weights=compute_sample_weight('balanced',Y_train[:,target_idx])\n",
    "    \n",
    "    #Convert to R objects\n",
    "    rX_train = robjects.r.matrix(robjects.FloatVector(X_train.T.ravel()), nrow=X_train.shape[0],\n",
    "                                 ncol=X_train.shape[1])\n",
    "    rY_train=robjects.FactorVector(pd.Series(Y_train[:,target_idx]).astype('str').values)\n",
    "    rX_test = robjects.r.matrix(robjects.FloatVector(X_test.T.ravel()), nrow=X_test.shape[0],\n",
    "                                ncol=X_test.shape[1])\n",
    "    rweights=robjects.FloatVector(weights.ravel())\n",
    "    \n",
    "    #Glmnet fit\n",
    "    fit=glmnet.glmnet(rX_train,rY_train,family = 'binomial',weights=rweights,alpha=1,\n",
    "                      **{'lambda':0,\n",
    "                         #Comment the next line out for unconstrained model\n",
    "                         'lower.limits':0,\n",
    "                         'standardize':False,'trace.it':1})\n",
    "\n",
    "    coefs=pandas2ri.rpy2py(robjects.r.matrix(fit.rx2['beta']))\n",
    "\n",
    "    N_features.append((coefs>0).sum())\n",
    "    \n",
    "    #Predict proba and convert to predict\n",
    "    Y_p=robjects.r.predict(fit,rX_test,type=\"response\",s=1)\n",
    "\n",
    "    Y_p=pandas2ri.rpy2py(Y_p)\n",
    "    \n",
    "    Y_predicted_target=Y_p.copy()\n",
    "    Y_predicted_target[Y_predicted_target>0.5]=1\n",
    "    Y_predicted_target[Y_predicted_target<=0.5]=0\n",
    "    Y_predicted.append(Y_predicted_target.ravel())\n",
    "Y_predicted=np.array(Y_predicted).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of positive weights model and unconstrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Positive weights model\n",
      "   precision  recall  F_score  support      Group\n",
      "0       0.70    0.61     0.66     31.0     no_agg\n",
      "1       0.00    0.00     0.00      4.0  disappear\n",
      "2       0.42    0.45     0.43     11.0     stream\n",
      "3       0.47    0.53     0.50     17.0        lag\n",
      "4       0.44    0.62     0.52     13.0        tag\n",
      "5       0.10    0.20     0.13      5.0        tip\n",
      "6       0.50    0.36     0.42     11.0       slug\n",
      "7       0.11    0.33     0.17      3.0       mhat\n",
      "8       0.75    1.00     0.86      6.0        cul\n",
      "9       0.50    0.80     0.62      5.0         FB\n",
      "\n",
      "N used features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "no_agg       2375\n",
       "disappear    2048\n",
       "stream       2205\n",
       "lag          2242\n",
       "tag          2078\n",
       "tip          2375\n",
       "slug         2038\n",
       "mhat         2060\n",
       "cul          2210\n",
       "FB           2310\n",
       "dtype: int64"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print F scores and N features\n",
    "print('\\nPositive weights model')\n",
    "prfs=pd.DataFrame(precision_recall_fscore_support(Y_test, Y_predicted),index=['precision','recall','F_score','support']).T\n",
    "prfs['Group']=order\n",
    "print(prfs.round(2))\n",
    "print()\n",
    "print('N used features')\n",
    "pd.Series(N_features,index=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unconstrained weights model\n",
      "   precision  recall  F_score  support      Group\n",
      "0       0.73    0.77     0.75     31.0     no_agg\n",
      "1       0.29    0.50     0.36      4.0  disappear\n",
      "2       0.67    0.55     0.60     11.0     stream\n",
      "3       0.44    0.41     0.42     17.0        lag\n",
      "4       0.53    0.62     0.57     13.0        tag\n",
      "5       0.00    0.00     0.00      5.0        tip\n",
      "6       0.33    0.27     0.30     11.0       slug\n",
      "7       0.43    1.00     0.60      3.0       mhat\n",
      "8       0.60    0.50     0.55      6.0        cul\n",
      "9       0.00    0.00     0.00      5.0         FB\n",
      "\n",
      "N used features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "no_agg       6220\n",
       "disappear    6202\n",
       "stream       6291\n",
       "lag          6230\n",
       "tag          6232\n",
       "tip          6286\n",
       "slug         6302\n",
       "mhat         6182\n",
       "cul          6254\n",
       "FB           6280\n",
       "dtype: int64"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation to be used after unconstrained model was fitted\n",
    "print('\\nUnconstrained weights model')\n",
    "prfs=pd.DataFrame(precision_recall_fscore_support(Y_test, Y_predicted),index=['precision','recall','F_score','support']).T\n",
    "prfs['Group']=order\n",
    "print(prfs.round(2))\n",
    "print()\n",
    "print('N used features')\n",
    "pd.Series(N_features,index=order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models perform worse than sklearn models (even when weights are unconstrained). They also use less features, even when there is no regularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
