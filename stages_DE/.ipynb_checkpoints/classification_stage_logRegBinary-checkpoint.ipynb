{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenotype classification  with logistic regression\n",
    "In order to predict phenotypes from expression data and select important developmental genes a multi-target/multi-label classification method was used: logistic regression based binary relevance classifier.  Binary relevance constructs a model for each target separately and then predicts the final label set as a union of predictions from target feature specific models. To perform feature (gene) selection l1 regularisation was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from importlib import reload\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0,module_path)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from skmultilearn.problem_transform import ClassifierChain, BinaryRelevance\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support,roc_auc_score\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "import sklearn.preprocessing as pp\n",
    "import altair as alt\n",
    "#alt.renderers.enable('notebook')\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import stages_DE.stages_library\n",
    "import importlib\n",
    "importlib.reload(stages_DE.stages_library)\n",
    "\n",
    "from networks.functionsDENet import loadPickle,savePickle\n",
    "from stages_DE.stages_library import PHENOTYPES, summary_classification, summary_classification_print_sort, scatter_catgory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteus=True\n",
    "if proteus:\n",
    "    pathClassification = '/home/khrovatin/timeTrajectoriesNet/data/stages/classification/'\n",
    "    dataPath= '/home/khrovatin/timeTrajectoriesNet/data/RPKUM/'\n",
    "else:\n",
    "    pathClassification = '/home/karin/Documents/timeTrajectories/data/stages/classification/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = pd.read_csv(dataPath + 'mergedGenes_RPKUM.tsv', sep='\\t', index_col=0)\n",
    "conditions = pd.read_csv(dataPath + 'conditions_mergedGenes.tsv', sep='\\t', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest_strains=['AX4', 'MybBGFP', 'ecmARm', 'gtaI', 'cudA', 'dgcA', 'gtaG', 'tagB',\n",
    "       'comH',  'gtaC', 'mybB','amiB', 'acaA']\n",
    "arrestPkaC_strains=['AX4', 'MybBGFP', 'ecmARm', 'gtaI', 'cudA', 'dgcA', 'gtaG', 'tagB',\n",
    "       'comH',  'gtaC', 'mybB','amiB', 'acaA', 'acaAPkaCoe', 'ac3PkaCoe', 'PkaCoe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N all samples: 486 \tN samples with phenotypic annotation: 344\n",
      "N all WT samples: 112 \tN WT samples with phenotypic annotation: 69\n",
      "N all arrest samples: 322 \tN arrest samples with phenotypic annotation: 216\n",
      "N all arrest+PkaC samples: 382 \tN arrest+PkaC samples with phenotypic annotation: 251\n"
     ]
    }
   ],
   "source": [
    "print('N all samples:',conditions.shape[0],\n",
    "      '\\tN samples with phenotypic annotation:',(conditions[PHENOTYPES] != 0).any(axis=1).sum())\n",
    "\n",
    "print('N all WT samples:',conditions.query('Group ==\"WT\"').shape[0],\n",
    "     '\\tN WT samples with phenotypic annotation:',(conditions.query('Group ==\"WT\"')[PHENOTYPES] != 0).any(axis=1).sum())\n",
    "\n",
    "print('N all arrest samples:',conditions[conditions.Strain.isin(arrest_strains)].shape[0],\n",
    "     '\\tN arrest samples with phenotypic annotation:',\n",
    "      (conditions[conditions.Strain.isin(arrest_strains)][PHENOTYPES] != 0).any(axis=1).sum())\n",
    "\n",
    "print('N all arrest+PkaC samples:',conditions[conditions.Strain.isin(arrestPkaC_strains)].shape[0],\n",
    "     '\\tN arrest+PkaC samples with phenotypic annotation:',\n",
    "      (conditions[conditions.Strain.isin(arrestPkaC_strains)][PHENOTYPES] != 0).any(axis=1).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples that have annotations include samples with images and samples at t=0, as those are all no_agg. WT samples are AX4 and MybBGFP. Henceforth only samples that have annotations will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain samples that have a phenotypic annotation\n",
    "def retain_annotated(genes,conditions):\n",
    "    Y_retained = conditions[(conditions[PHENOTYPES] != 0).any(axis=1)]\n",
    "    X_retained = genes[Y_retained.Measurment].T.values\n",
    "    return(X_retained,Y_retained)\n",
    "\n",
    "X,Y = retain_annotated(genes,conditions)\n",
    "X_WT,Y_WT = retain_annotated(genes,conditions.query('Group ==\"WT\"'))\n",
    "X_arrest,Y_arrest = retain_annotated(genes,conditions[conditions.Strain.isin(arrest_strains)])\n",
    "X_arrestPkaC,Y_arrestPkaC = retain_annotated(genes,conditions[conditions.Strain.isin(arrestPkaC_strains)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-affe7adeb2a24d9fa7b8365342ce504c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-affe7adeb2a24d9fa7b8365342ce504c\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"facet\": {\"spacing\": 0}}, \"data\": {\"name\": \"data-11ac691e9a0283d7662f6c5afe20a09c\"}, \"facet\": {\"column\": {\"type\": \"nominal\", \"field\": \"Phenotype\", \"header\": {\"labelOrient\": \"bottom\", \"titleOrient\": \"bottom\"}, \"sort\": [\"no_agg\", \"stream\", \"lag\", \"tag\", \"tip\", \"slug\", \"mhat\", \"cul\", \"FB\", \"disappear\", \"tag_spore\"]}}, \"spec\": {\"layer\": [{\"mark\": \"bar\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Group\"}, \"x\": {\"type\": \"nominal\", \"axis\": {\"grid\": false, \"labels\": false, \"ticks\": true, \"values\": [0]}, \"field\": \"Group\", \"title\": null}, \"y\": {\"type\": \"quantitative\", \"field\": \"Count\"}}, \"width\": 70}, {\"mark\": {\"type\": \"text\", \"dy\": -5}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Group\"}, \"text\": {\"type\": \"quantitative\", \"field\": \"Count\"}, \"x\": {\"type\": \"nominal\", \"axis\": {\"grid\": false, \"labels\": false, \"ticks\": true, \"values\": [0]}, \"field\": \"Group\", \"title\": null}, \"y\": {\"type\": \"quantitative\", \"field\": \"Count\"}}, \"width\": 70}]}, \"title\": \"N samples for individual phenotypes across strain groups\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-11ac691e9a0283d7662f6c5afe20a09c\": [{\"Phenotype\": \"no_agg\", \"Count\": 153, \"Group\": \"all\"}, {\"Phenotype\": \"stream\", \"Count\": 54, \"Group\": \"all\"}, {\"Phenotype\": \"lag\", \"Count\": 80, \"Group\": \"all\"}, {\"Phenotype\": \"tag\", \"Count\": 63, \"Group\": \"all\"}, {\"Phenotype\": \"tip\", \"Count\": 23, \"Group\": \"all\"}, {\"Phenotype\": \"slug\", \"Count\": 56, \"Group\": \"all\"}, {\"Phenotype\": \"mhat\", \"Count\": 13, \"Group\": \"all\"}, {\"Phenotype\": \"cul\", \"Count\": 31, \"Group\": \"all\"}, {\"Phenotype\": \"FB\", \"Count\": 22, \"Group\": \"all\"}, {\"Phenotype\": \"disappear\", \"Count\": 19, \"Group\": \"all\"}, {\"Phenotype\": \"tag_spore\", \"Count\": 3, \"Group\": \"all\"}, {\"Phenotype\": \"no_agg\", \"Count\": 14, \"Group\": \"WT\"}, {\"Phenotype\": \"stream\", \"Count\": 9, \"Group\": \"WT\"}, {\"Phenotype\": \"lag\", \"Count\": 13, \"Group\": \"WT\"}, {\"Phenotype\": \"tag\", \"Count\": 10, \"Group\": \"WT\"}, {\"Phenotype\": \"tip\", \"Count\": 4, \"Group\": \"WT\"}, {\"Phenotype\": \"slug\", \"Count\": 15, \"Group\": \"WT\"}, {\"Phenotype\": \"mhat\", \"Count\": 9, \"Group\": \"WT\"}, {\"Phenotype\": \"cul\", \"Count\": 17, \"Group\": \"WT\"}, {\"Phenotype\": \"FB\", \"Count\": 9, \"Group\": \"WT\"}, {\"Phenotype\": \"disappear\", \"Count\": 0, \"Group\": \"WT\"}, {\"Phenotype\": \"tag_spore\", \"Count\": 0, \"Group\": \"WT\"}, {\"Phenotype\": \"no_agg\", \"Count\": 95, \"Group\": \"arrest\"}, {\"Phenotype\": \"stream\", \"Count\": 24, \"Group\": \"arrest\"}, {\"Phenotype\": \"lag\", \"Count\": 39, \"Group\": \"arrest\"}, {\"Phenotype\": \"tag\", \"Count\": 36, \"Group\": \"arrest\"}, {\"Phenotype\": \"tip\", \"Count\": 13, \"Group\": \"arrest\"}, {\"Phenotype\": \"slug\", \"Count\": 43, \"Group\": \"arrest\"}, {\"Phenotype\": \"mhat\", \"Count\": 13, \"Group\": \"arrest\"}, {\"Phenotype\": \"cul\", \"Count\": 19, \"Group\": \"arrest\"}, {\"Phenotype\": \"FB\", \"Count\": 11, \"Group\": \"arrest\"}, {\"Phenotype\": \"disappear\", \"Count\": 0, \"Group\": \"arrest\"}, {\"Phenotype\": \"tag_spore\", \"Count\": 0, \"Group\": \"arrest\"}, {\"Phenotype\": \"no_agg\", \"Count\": 111, \"Group\": \"arrest_PkaC\"}, {\"Phenotype\": \"stream\", \"Count\": 31, \"Group\": \"arrest_PkaC\"}, {\"Phenotype\": \"lag\", \"Count\": 46, \"Group\": \"arrest_PkaC\"}, {\"Phenotype\": \"tag\", \"Count\": 47, \"Group\": \"arrest_PkaC\"}, {\"Phenotype\": \"tip\", \"Count\": 21, \"Group\": \"arrest_PkaC\"}, {\"Phenotype\": \"slug\", \"Count\": 52, \"Group\": \"arrest_PkaC\"}, {\"Phenotype\": \"mhat\", \"Count\": 13, \"Group\": \"arrest_PkaC\"}, {\"Phenotype\": \"cul\", \"Count\": 31, \"Group\": \"arrest_PkaC\"}, {\"Phenotype\": \"FB\", \"Count\": 21, \"Group\": \"arrest_PkaC\"}, {\"Phenotype\": \"disappear\", \"Count\": 0, \"Group\": \"arrest_PkaC\"}, {\"Phenotype\": \"tag_spore\", \"Count\": 0, \"Group\": \"arrest_PkaC\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheno_count=pd.DataFrame()\n",
    "for Y_data,group in zip([Y,Y_WT,Y_arrest,Y_arrestPkaC],['all','WT','arrest','arrest_PkaC']):\n",
    "    plot_data=pd.DataFrame(Y_data[PHENOTYPES].sum().astype('int')).reset_index()\n",
    "    plot_data.columns=['Phenotype','Count']\n",
    "    plot_data['Group']=[group]*plot_data.shape[0]\n",
    "    pheno_count=pheno_count.append(plot_data)\n",
    "\n",
    "\n",
    "base=alt.Chart(pheno_count,width=70).encode(\n",
    "    x=alt.X('Group',title=None,axis=alt.Axis(values=[0], ticks=True, grid=False, labels=False)),\n",
    "    y='Count',\n",
    "    color='Group',\n",
    ")\n",
    "\n",
    "alt.layer(\n",
    "  base.mark_bar(),\n",
    "  base.mark_text(dy=-5).encode(text='Count')\n",
    ").facet(\n",
    "  column=alt.Column('Phenotype', sort=PHENOTYPES,header=alt.Header(titleOrient='bottom',labelOrient='bottom'))\n",
    ").configure_facet(spacing=0).properties(\n",
    "    title='N samples for individual phenotypes across strain groups'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tag_spore has too little samples to be predicted. Nevertheless, samples with tag_spore annotation among their annotations can still be used. Some samples will thus have 0 labels in all targets.  Similarly, for WT stages tag_spore, disappera, and tip would need to be removed; and for arrest and arrest_PkaC disappear and tag_spore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove targets (Phenoptypes) with too little samples\n",
    "def remove_rare(Y_data,min_n):\n",
    "    order_data=list(Y_data[PHENOTYPES].sum().astype('int').loc[lambda x: x >= min_n].index)\n",
    "    Y_data=Y_data[order_data].values\n",
    "    return(Y_data,order_data)\n",
    "\n",
    "Y,order=remove_rare(Y,9)\n",
    "Y_WT,order_WT=remove_rare(Y_WT,9)\n",
    "Y_arrest,order_arrest=remove_rare(Y_arrest,9)\n",
    "Y_arrestPkaC,order_arrestPkaC=remove_rare(Y_arrestPkaC,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-e69c7af748ce402388f237e1b5c3c669\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-e69c7af748ce402388f237e1b5c3c669\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"facet\": {\"spacing\": 0}}, \"data\": {\"name\": \"data-1b45fa59e04b2c5219c0f7fddffdca12\"}, \"facet\": {\"column\": {\"type\": \"quantitative\", \"field\": \"N annotated phenotypes\", \"header\": {\"labelOrient\": \"bottom\", \"titleOrient\": \"bottom\"}, \"sort\": [\"no_agg\", \"stream\", \"lag\", \"tag\", \"tip\", \"slug\", \"mhat\", \"cul\", \"FB\", \"disappear\", \"tag_spore\"]}}, \"spec\": {\"layer\": [{\"mark\": \"bar\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Group\"}, \"x\": {\"type\": \"nominal\", \"axis\": {\"grid\": false, \"labels\": false, \"ticks\": true, \"values\": [0]}, \"field\": \"Group\", \"title\": null}, \"y\": {\"type\": \"quantitative\", \"field\": \"Count\"}}, \"width\": 70}, {\"mark\": {\"type\": \"text\", \"dy\": -5}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Group\"}, \"text\": {\"type\": \"quantitative\", \"field\": \"Count\"}, \"x\": {\"type\": \"nominal\", \"axis\": {\"grid\": false, \"labels\": false, \"ticks\": true, \"values\": [0]}, \"field\": \"Group\", \"title\": null}, \"y\": {\"type\": \"quantitative\", \"field\": \"Count\"}}, \"width\": 70}]}, \"title\": \"Distribution of N phenotypes annotated to each sample acorss strain groups\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-1b45fa59e04b2c5219c0f7fddffdca12\": [{\"N annotated phenotypes\": 0.0, \"Count\": 3, \"Group\": \"all\"}, {\"N annotated phenotypes\": 1.0, \"Count\": 211, \"Group\": \"all\"}, {\"N annotated phenotypes\": 2.0, \"Count\": 99, \"Group\": \"all\"}, {\"N annotated phenotypes\": 3.0, \"Count\": 25, \"Group\": \"all\"}, {\"N annotated phenotypes\": 4.0, \"Count\": 1, \"Group\": \"all\"}, {\"N annotated phenotypes\": 5.0, \"Count\": 4, \"Group\": \"all\"}, {\"N annotated phenotypes\": 6.0, \"Count\": 1, \"Group\": \"all\"}, {\"N annotated phenotypes\": 0.0, \"Count\": 2, \"Group\": \"WT\"}, {\"N annotated phenotypes\": 1.0, \"Count\": 40, \"Group\": \"WT\"}, {\"N annotated phenotypes\": 2.0, \"Count\": 25, \"Group\": \"WT\"}, {\"N annotated phenotypes\": 3.0, \"Count\": 2, \"Group\": \"WT\"}, {\"N annotated phenotypes\": 1.0, \"Count\": 148, \"Group\": \"arrest\"}, {\"N annotated phenotypes\": 2.0, \"Count\": 59, \"Group\": \"arrest\"}, {\"N annotated phenotypes\": 3.0, \"Count\": 9, \"Group\": \"arrest\"}, {\"N annotated phenotypes\": 1.0, \"Count\": 158, \"Group\": \"arrest_PkaC\"}, {\"N annotated phenotypes\": 2.0, \"Count\": 75, \"Group\": \"arrest_PkaC\"}, {\"N annotated phenotypes\": 3.0, \"Count\": 13, \"Group\": \"arrest_PkaC\"}, {\"N annotated phenotypes\": 5.0, \"Count\": 4, \"Group\": \"arrest_PkaC\"}, {\"N annotated phenotypes\": 6.0, \"Count\": 1, \"Group\": \"arrest_PkaC\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_count=pd.DataFrame()\n",
    "for Y_data,group in zip([Y,Y_WT,Y_arrest,Y_arrestPkaC],['all','WT','arrest','arrest_PkaC']):\n",
    "    plot_data=pd.DataFrame(pd.DataFrame(pd.DataFrame(Y_data).sum(axis=1)).groupby(0).size(),columns=['Count']).reset_index()\n",
    "    plot_data.columns=['N annotated phenotypes','Count']\n",
    "    plot_data['Group']=[group]*plot_data.shape[0]\n",
    "    target_count=target_count.append(plot_data)\n",
    "\n",
    "base=alt.Chart(target_count,width=70).encode(\n",
    "    x=alt.X('Group',title=None,axis=alt.Axis(values=[0], ticks=True, grid=False, labels=False)),\n",
    "    y='Count',\n",
    "    color='Group',\n",
    ")\n",
    "\n",
    "alt.layer(\n",
    "  base.mark_bar(),\n",
    "  base.mark_text(dy=-5).encode(text='Count')\n",
    ").facet(\n",
    "  column=alt.Column('N annotated phenotypes', sort=PHENOTYPES,header=alt.Header(titleOrient='bottom',labelOrient='bottom'))\n",
    ").configure_facet(spacing=0).properties(\n",
    "    title='Distribution of N phenotypes annotated to each sample acorss strain groups'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N features (genes): 12828 \tN constant features: 400\n",
      "N WT features (genes): 12828 \tN constant WT features: 505\n",
      "N arrest features (genes): 12828 \tN constant arrest features: 404\n",
      "N arrest+PkaC features (genes): 12828 \tN constant arrest+PkaC features: 402\n"
     ]
    }
   ],
   "source": [
    "print('N features (genes):',X.shape[1],'\\tN constant features:',(X.std(axis=0)==0).sum())\n",
    "print('N WT features (genes):',X_WT.shape[1],'\\tN constant WT features:',(X_WT.std(axis=0)==0).sum())\n",
    "print('N arrest features (genes):',X_arrest.shape[1],\n",
    "      '\\tN constant arrest features:',(X_arrest.std(axis=0)==0).sum())\n",
    "print('N arrest+PkaC features (genes):',X_arrestPkaC.shape[1],\n",
    "      '\\tN constant arrest+PkaC features:',(X_arrestPkaC.std(axis=0)==0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting and performance statistic calculation\n",
    "Models (with and without regularisation) are fit using five-fold cross validation. Saved metrics: F_score, precision, recall, and N used features (and micro averaged ROC_AUC score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 9) (251, 12426) 9\n"
     ]
    }
   ],
   "source": [
    "# Which data to model (WT or all strains)\n",
    "X_model=X_arrestPkaC.copy()\n",
    "Y_model=Y_arrestPkaC.copy()\n",
    "order_model=order_arrestPkaC.copy()\n",
    "# Remove constant features\n",
    "X_model=X_model[:,(X_model.std(axis=0)!=0)]\n",
    "print(Y_model.shape,X_model.shape,len(order_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prfs_all=pd.DataFrame()\n",
    "rac_all=pd.DataFrame()\n",
    "feats_all=pd.DataFrame()\n",
    "split = IterativeStratification(n_splits=5, order=1)\n",
    "fold=0\n",
    "                \n",
    "# Cross validation\n",
    "for train_index, test_index in split.split(X_model, Y_model):\n",
    "    fold += 1\n",
    "    print(fold)\n",
    "    scaler = pp.MinMaxScaler()\n",
    "    #Scale X features to [0,1], use X_train_fold scaller to also scale X_test_fold\n",
    "    X_train_fold, X_test_fold = X_model[train_index], X_model[test_index]\n",
    "    Y_train_fold, Y_test_fold = Y_model[train_index], Y_model[test_index]\n",
    "    X_train_fold=scaler.fit_transform(X_train_fold)\n",
    "    X_test_fold=scaler.transform(X_test_fold)\n",
    "    # Different regularization strengths - none or 1 \n",
    "    for params in [\n",
    "        {'penalty':'none','class_weight':'balanced'}\n",
    "        #,{'penalty':'none'}\n",
    "                  # ,{'penalty':'l1','C':0.6,'class_weight':'balanced'}\n",
    "        #,{'penalty':'l1','C':0.7}\n",
    "                  ]:\n",
    "        c=''\n",
    "        for param_value in params.values():\n",
    "            c=c+str(param_value)+'_'\n",
    "        c=c.rstrip('_')\n",
    "        print('C:',c)\n",
    "        classifier = OneVsRestClassifier(\n",
    "            # saga is only solver that supports no penaly and penalty = l1. \n",
    "            estimator=LogisticRegression( n_jobs=20,  solver='saga',**params),\n",
    "            n_jobs=Y_model.shape[1]).fit(X_train_fold,Y_train_fold)\n",
    "        \n",
    "        # Quality metrics for the model\n",
    "        Y_predict_fold = classifier.predict(X_test_fold)\n",
    "        Y_p_fold = classifier.predict_proba(X_test_fold)\n",
    "        \n",
    "        prfs=pd.DataFrame(precision_recall_fscore_support(Y_test_fold, Y_predict_fold),index=['precision','recall','F_score','support']).T\n",
    "        prfs['Group']=order_model\n",
    "        prfs['params']=[c]*prfs.shape[0]\n",
    "        prfs_all=prfs_all.append(prfs)\n",
    "        prfs=list(precision_recall_fscore_support(Y_test_fold, Y_predict_fold, average='micro'))\n",
    "        prfs.extend(['micro',c])\n",
    "        prfs=dict(zip(['precision','recall','F_score','support','Group',\"params\"],prfs))\n",
    "        prfs_all = prfs_all.append( prfs,ignore_index=True)\n",
    "        prfs=list(precision_recall_fscore_support(Y_test_fold, Y_predict_fold, average='macro'))\n",
    "        prfs.extend(['macro',c])\n",
    "        prfs=dict(zip(['precision','recall','F_score','support','Group',\"params\"],prfs))\n",
    "        prfs_all = prfs_all.append( prfs,ignore_index=True)\n",
    "        \n",
    "        rac=pd.DataFrame(roc_auc_score(Y_test_fold, Y_p_fold,average=None),columns=['roc_auc'])\n",
    "        rac['Group']=order_model\n",
    "        rac['params']=[c]*rac.shape[0]\n",
    "        rac_all = rac_all.append(rac,ignore_index=True)\n",
    "        rac=dict(zip(['roc_auc','Group','params'],[roc_auc_score(Y_test_fold, Y_p_fold, average='micro'),'micro',c]))\n",
    "        rac_all=rac_all.append(rac,ignore_index=True)\n",
    "        rac=dict(zip(['roc_auc','Group','params'],[roc_auc_score(Y_test_fold, Y_p_fold, average='macro'),'macro',c]))\n",
    "        rac_all=rac_all.append(rac,ignore_index=True)\n",
    "        \n",
    "        # N used features in the model\n",
    "        feats_combined = set()\n",
    "        for i in range(len(order_model)):\n",
    "            cl = classifier.estimators_[i]\n",
    "            feats_stage = set(pd.Series(range(X_model.shape[1]))[(cl.coef_ != 0).flatten()[:X_model.shape[1]]].index)\n",
    "            feats_combined = feats_combined | feats_stage\n",
    "            #print(len(feats_stage), len(feats_combined))\n",
    "            feats=dict(zip(['N_features','params','Group'],[len(feats_stage),c,order_model[i]]))\n",
    "            feats_all=feats_all.append(feats,ignore_index=True)\n",
    "        feats= dict(zip(['N_features', 'params', 'Group'],[len(feats_combined), c, 'all']))\n",
    "        feats_all = feats_all.append(feats,ignore_index=True)\n",
    "savePickle(pathClassification+'logisticRegressionBinaryRelevanceComparisonArrestPkaC.pkl',{'prfs':prfs_all,'rac':rac_all,'featsN':feats_all})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model names component: l1_C - l1 regularization with regularization constant (C) writted anfter underscore, none - no regularisation, balanced - balanced weights for labels (0,1) within targets/phenotypes. \n",
    "Summary statistics averages: micro - over all samples, macro - over pre-calculated statistics of all target features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=loadPickle(pathClassification+'logisticRegressionBinaryRelevanceComparison.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F score is a harmonic mean of precision (true predicted positives/all predicted positives) and recall (true predicted positives/all true positives). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F score summary for OvR logistic regression: none_balanced\n",
      "Mean cross validation F score averaged across all phenotypes and standard error\n",
      "macro       0.71  +- 0.01\n",
      "micro       0.75  +- 0.01\n",
      "Mean cross validation F score of individual phenotypes and standard error\n",
      "no_agg      0.87  +- 0.01\n",
      "cul         0.83  +- 0.04\n",
      "mhat        0.82  +- 0.06\n",
      "slug        0.75  +- 0.03\n",
      "lag         0.75  +- 0.04\n",
      "FB          0.69  +- 0.03\n",
      "tag         0.68  +- 0.05\n",
      "disappear   0.61  +- 0.08\n",
      "tip         0.58  +- 0.09\n",
      "stream      0.57  +- 0.04\n",
      "\n",
      "\n",
      "F score summary for OvR logistic regression: l1_0.6_balanced\n",
      "Mean cross validation F score averaged across all phenotypes and standard error\n",
      "macro       0.65  +- 0.02\n",
      "micro       0.70  +- 0.02\n",
      "Mean cross validation F score of individual phenotypes and standard error\n",
      "no_agg      0.86  +- 0.02\n",
      "cul         0.74  +- 0.06\n",
      "lag         0.73  +- 0.04\n",
      "slug        0.67  +- 0.02\n",
      "tag         0.66  +- 0.04\n",
      "FB          0.64  +- 0.03\n",
      "stream      0.61  +- 0.03\n",
      "mhat        0.55  +- 0.02\n",
      "tip         0.55  +- 0.07\n",
      "disappear   0.50  +- 0.06\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_prfs=result['prfs'].groupby('params')\n",
    "#for group in ['none','none_balanced','l1_0.6_balanced']:\n",
    "for group in ['none_balanced','l1_0.6_balanced']:\n",
    "    data=data_prfs.get_group(group)\n",
    "    summary=summary_classification(data,'F_score',\"Group\",print_df=False)\n",
    "    print('F score summary for OvR logistic regression:',group)\n",
    "    summary_classification_print_sort(summary,statistic='F score',averages=['macro','micro'],groups=order)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F score summary for OvR logistic regression with arrest  strains data: none_balanced\n",
      "Mean cross validation F score averaged across all phenotypes and standard error\n",
      "macro       0.75  +- 0.02\n",
      "micro       0.82  +- 0.01\n",
      "Mean cross validation F score of individual phenotypes and standard error\n",
      "no_agg      0.94  +- 0.02\n",
      "slug        0.89  +- 0.02\n",
      "cul         0.83  +- 0.03\n",
      "mhat        0.82  +- 0.07\n",
      "FB          0.79  +- 0.10\n",
      "lag         0.78  +- 0.04\n",
      "tag         0.76  +- 0.06\n",
      "stream      0.55  +- 0.10\n",
      "tip         0.41  +- 0.17\n",
      "\n",
      "\n",
      "F score summary for OvR logistic regression with arrest+PkaC  strains data: none_balanced\n",
      "Mean cross validation F score averaged across all phenotypes and standard error\n",
      "macro       0.77  +- 0.02\n",
      "micro       0.81  +- 0.02\n",
      "Mean cross validation F score of individual phenotypes and standard error\n",
      "no_agg      0.92  +- 0.02\n",
      "cul         0.85  +- 0.06\n",
      "mhat        0.80  +- 0.08\n",
      "slug        0.78  +- 0.02\n",
      "FB          0.78  +- 0.04\n",
      "lag         0.76  +- 0.04\n",
      "tag         0.76  +- 0.04\n",
      "stream      0.68  +- 0.08\n",
      "tip         0.59  +- 0.08\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file,strain_group in zip(['logisticRegressionBinaryRelevanceComparisonArrest.pkl',\n",
    "                             'logisticRegressionBinaryRelevanceComparisonArrestPkaC.pkl'],\n",
    "                             ['arrest','arrest+PkaC']):\n",
    "    result2=loadPickle(pathClassification+file)\n",
    "    data_prfs=result2['prfs'].groupby('params')\n",
    "    #for group in ['none_balanced']:\n",
    "    for group in ['none_balanced']:\n",
    "        data=data_prfs.get_group(group)\n",
    "        summary=summary_classification(data,'F_score',\"Group\",print_df=False)\n",
    "        print('F score summary for OvR logistic regression with',strain_group,' strains data:',group)\n",
    "        summary_classification_print_sort(summary,statistic='F score',averages=['macro','micro'],groups=order)\n",
    "        print('\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rac=result['rac'].groupby('params')\n",
    "for group in ['none','none_balanced','l1_0.6_balanced']:\n",
    "    data=data_rac.get_group(group)\n",
    "    summary=summary_classification(data,'roc_auc',\"Group\",print_df=False)\n",
    "    print('ROC_AUC score summary for OvR logistic regression:',group)\n",
    "    summary_classification_print_sort(summary,statistic='roc_auc',averages=['macro','micro'],groups=order)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance varies highly across target variables (phenotypes). \n",
    "\n",
    "The F score of the balanced model (labels (0,1) are weighted based on their proportion in a target) is better.\n",
    "\n",
    "Performance of non-regularized model is better than the one with the chosen regularisation constant. However, the regularisation constant was not tuned on this dataset. It is very likely that a somehwat higher regularisation constant (leading to inclusion of more genes/features) would yeald results comparable to the non-regularised dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N used features in OvR logistic regression: none_balanced\n",
      "Mean cross validation N features averaged across all phenotypes and standard error\n",
      "all         12426.00+- 0.63\n",
      "Mean cross validation N features of individual phenotypes and standard error\n",
      "FB          12426.00+- 0.63\n",
      "cul         12426.00+- 0.63\n",
      "disappear   12426.00+- 0.63\n",
      "lag         12426.00+- 0.63\n",
      "mhat        12426.00+- 0.63\n",
      "no_agg      12426.00+- 0.63\n",
      "slug        12426.00+- 0.63\n",
      "stream      12426.00+- 0.63\n",
      "tag         12426.00+- 0.63\n",
      "tip         12426.00+- 0.63\n",
      "\n",
      "\n",
      "N used features in OvR logistic regression: l1_0.6_balanced\n",
      "Mean cross validation N features averaged across all phenotypes and standard error\n",
      "all         7183.20+- 1281.84\n",
      "Mean cross validation N features of individual phenotypes and standard error\n",
      "disappear   5054.20+- 1921.89\n",
      "tag         731.60+- 13.45\n",
      "slug        721.00+- 12.08\n",
      "lag         709.00+- 11.67\n",
      "cul         702.80+- 13.65\n",
      "stream      700.80+- 17.46\n",
      "tip         692.00+- 20.03\n",
      "FB          669.80+- 12.91\n",
      "mhat        662.80+- 14.11\n",
      "no_agg      661.00+- 22.28\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_feats=result['featsN'].groupby('params')\n",
    "#for group in ['none','none_balanced','l1_0.6_balanced']:\n",
    "for group in ['none_balanced','l1_0.6_balanced']:\n",
    "    data=data_feats.get_group(group)\n",
    "    summary=summary_classification(data,'N_features',\"Group\",print_df=False)\n",
    "    print('N used features in OvR logistic regression:',group)\n",
    "    summary_classification_print_sort(summary,statistic='N features',averages=['all'],groups=order)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization highly reduces the number of features used for classification of all phenotypes. The disappear phneotype is an except (in non balanced regularised model this phenotype also had lower and less variable N of selected features). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance on WT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_WT=loadPickle(pathClassification+'logisticRegressionBinaryRelevanceComparisonWT.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F score summary for OvR logistic regression: none_balanced\n",
      "Mean cross validation F score averaged across all phenotypes and standard error\n",
      "macro       0.81  +- 0.03\n",
      "micro       0.82  +- 0.02\n",
      "Mean cross validation F score of individual phenotypes and standard error\n",
      "no_agg      0.90  +- 0.07\n",
      "cul         0.88  +- 0.06\n",
      "lag         0.86  +- 0.06\n",
      "mhat        0.86  +- 0.10\n",
      "FB          0.79  +- 0.06\n",
      "slug        0.77  +- 0.06\n",
      "stream      0.75  +- 0.08\n",
      "tag         0.66  +- 0.05\n",
      "\n",
      "\n",
      "F score summary for OvR logistic regression: l1_0.8_balanced\n",
      "Mean cross validation F score averaged across all phenotypes and standard error\n",
      "macro       0.77  +- 0.03\n",
      "micro       0.78  +- 0.03\n",
      "Mean cross validation F score of individual phenotypes and standard error\n",
      "lag         0.90  +- 0.04\n",
      "no_agg      0.88  +- 0.06\n",
      "cul         0.85  +- 0.05\n",
      "FB          0.80  +- 0.08\n",
      "slug        0.74  +- 0.07\n",
      "mhat        0.73  +- 0.07\n",
      "stream      0.68  +- 0.11\n",
      "tag         0.60  +- 0.08\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_prfs=result_WT['prfs'].groupby('params')\n",
    "#for group in ['none','none_balanced','l1_0.8_balanced']:\n",
    "for group in ['none_balanced','l1_0.8_balanced']:\n",
    "    data=data_prfs.get_group(group)\n",
    "    summary=summary_classification(data,'F_score',\"Group\",print_df=False)\n",
    "    print('F score summary for OvR logistic regression:',group)\n",
    "    summary_classification_print_sort(summary,statistic='F score',averages=['macro','micro'],groups=order)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using only WT data the model performance is even higher. This might indicate metabolic differences between similarly looking phenotypes across strains. It might be interesting to perform l1 regularised logistic regression or other gene selection analysis on individual strain groups (if enought samples are availiable) and compare the selected genes between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N used features in OvR logistic regression: none_balanced\n",
      "Mean cross validation N features averaged across all phenotypes and standard error\n",
      "all         12307.00+- 1.30\n",
      "Mean cross validation N features of individual phenotypes and standard error\n",
      "FB          12307.00+- 1.30\n",
      "cul         12307.00+- 1.30\n",
      "lag         12307.00+- 1.30\n",
      "mhat        12307.00+- 1.30\n",
      "no_agg      12307.00+- 1.30\n",
      "slug        12307.00+- 1.30\n",
      "stream      12307.00+- 1.30\n",
      "tag         12307.00+- 1.30\n",
      "\n",
      "\n",
      "N used features in OvR logistic regression: l1_0.8_balanced\n",
      "Mean cross validation N features averaged across all phenotypes and standard error\n",
      "all         3612.80+- 29.68\n",
      "Mean cross validation N features of individual phenotypes and standard error\n",
      "no_agg      778.00+- 11.92\n",
      "cul         670.80+- 20.11\n",
      "mhat        670.00+- 15.50\n",
      "slug        612.80+- 8.96\n",
      "FB          611.20+- 8.65\n",
      "stream      578.60+- 5.82\n",
      "lag         577.40+- 6.56\n",
      "tag         571.60+- 8.59\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_feats=result_WT['featsN'].groupby('params')\n",
    "#for group in ['none','none_balanced','l1_0.8_balanced']:\n",
    "for group in ['none_balanced','l1_0.8_balanced']:\n",
    "    data=data_feats.get_group(group)\n",
    "    summary=summary_classification(data,'N_features',\"Group\",print_df=False)\n",
    "    print('N used features in OvR logistic regression:',group)\n",
    "    summary_classification_print_sort(summary,statistic='N features',averages=['all'],groups=order)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
