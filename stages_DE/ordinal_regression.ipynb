{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal logistic regression for phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from importlib import reload\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0,module_path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support,roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import sklearn.preprocessing as pp\n",
    "#alt.renderers.enable('notebook')\n",
    "from IPython.display import display\n",
    "from mord import LogisticAT\n",
    "\n",
    "import stages_DE.stages_library\n",
    "import importlib\n",
    "importlib.reload(stages_DE.stages_library)\n",
    "\n",
    "from networks.functionsDENet import loadPickle,savePickle\n",
    "from stages_DE.stages_library import PHENOTYPES, PHENOTYPES_X, summary_classification, summary_classification_print_sort, scatter_catgory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteus=True\n",
    "if proteus:\n",
    "    pathClassification = '/home/khrovatin/timeTrajectoriesNet/data/stages/classification/'\n",
    "    dataPath= '/home/khrovatin/timeTrajectoriesNet/data/RPKUM/'\n",
    "else:\n",
    "    pathClassification = '/home/karin/Documents/timeTrajectories/data/stages/classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = pd.read_csv(dataPath + 'mergedGenes_RPKUM.tsv', sep='\\t', index_col=0)\n",
    "conditions = pd.read_csv(dataPath + 'conditions_mergedGenes.tsv', sep='\\t', index_col=None)\n",
    "\n",
    "# Retain only samples with annotations\n",
    "Y = conditions[(conditions[PHENOTYPES] != 0).any(axis=1)]\n",
    "X = genes[Y.Measurment].T.values\n",
    "\n",
    "# Remove targets with too little positive samples\n",
    "order=PHENOTYPES.copy()\n",
    "order.remove('tag_spore')\n",
    "Y = Y[order].values\n",
    "\n",
    "# Remove constant features\n",
    "X=X[:,(X.std(axis=0)!=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As ordinal regression works on  single target multi class data the phenotype data (multi target, each with 2 classes - yes/no - multilabel data) must be transformed. For this a single target feature (1-N) was created. Sample was assigned a single value (1-N). If it had multiple annotated phenotypes (n) it was used multiple times (n-times) with different assignmnets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform multi-target data into single target data\n",
    "# (assign sample to each Y that it has annotated - some samples will be repeated)\n",
    "# Transform Y form multi target with labels {0,1} to single target with labels 1...N (ordered ints)\n",
    "X_transformed=[]\n",
    "Y_transformed=[]\n",
    "for idx_sample in range(Y.shape[0]):\n",
    "    y=Y[idx_sample,:]\n",
    "    x=X[idx_sample,:]\n",
    "    for idx_phenotype,phenotype in enumerate(order):\n",
    "        if y[idx_phenotype] ==1:\n",
    "            Y_transformed.append(PHENOTYPES_X[phenotype])\n",
    "            X_transformed.append(x)\n",
    "X_transformed=np.array(X_transformed)\n",
    "Y_transformed=np.array(Y_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Data is split using 5-fold cross validation, scaled to [0,1], and used for training/evaluation of ordinal logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prfs_all=pd.DataFrame()\n",
    "rac_all=pd.DataFrame()\n",
    "feats_all=pd.DataFrame()\n",
    "\n",
    "X_model=X_transformed.copy()\n",
    "Y_model=Y_transformed.copy()\n",
    "order_model=order.copy()\n",
    "\n",
    "split = StratifiedKFold(n_splits=5)\n",
    "fold=0\n",
    "                \n",
    "# Cross validation\n",
    "for train_index, test_index in split.split(X_model, Y_model):\n",
    "    fold += 1\n",
    "    print(fold)\n",
    "    scaler = pp.MinMaxScaler()\n",
    "    #Scale X features to [0,1], use X_train_fold scaller to also scale X_test_fold\n",
    "    X_train_fold, X_test_fold = X_model[train_index], X_model[test_index]\n",
    "    Y_train_fold, Y_test_fold = Y_model[train_index], Y_model[test_index]\n",
    "    X_train_fold=scaler.fit_transform(X_train_fold)\n",
    "    X_test_fold=scaler.transform(X_test_fold)\n",
    "    \n",
    "    classifier=LogisticAT().fit(X_train_fold,Y_train_fold)\n",
    "    \n",
    "    # Quality metrics for the model\n",
    "    Y_predict_fold = classifier.predict(X_test_fold)\n",
    "    Y_p_fold = classifier.predict_proba(X_test_fold)\n",
    "\n",
    "    prfs=pd.DataFrame(precision_recall_fscore_support(Y_test_fold, Y_predict_fold),index=['precision','recall','F_score','support']).T\n",
    "    prfs['Group']=order_model\n",
    "    prfs_all=prfs_all.append(prfs)\n",
    "    prfs=list(precision_recall_fscore_support(Y_test_fold, Y_predict_fold, average='micro'))\n",
    "    prfs.extend(['micro'])\n",
    "    prfs=dict(zip(['precision','recall','F_score','support','Group'],prfs))\n",
    "    prfs_all = prfs_all.append( prfs,ignore_index=True)\n",
    "    prfs=list(precision_recall_fscore_support(Y_test_fold, Y_predict_fold, average='macro'))\n",
    "    prfs.extend(['macro'])\n",
    "    prfs=dict(zip(['precision','recall','F_score','support','Group'],prfs))\n",
    "    prfs_all = prfs_all.append( prfs,ignore_index=True)\n",
    "\n",
    "    rac=dict(zip(['roc_auc','Group'],[roc_auc_score(Y_test_fold, Y_p_fold,multi_class='ovr',average='weighted'),'weighted_ovr']))\n",
    "    rac_all=rac_all.append(rac,ignore_index=True)\n",
    "    rac=dict(zip(['roc_auc','Group'],[roc_auc_score(Y_test_fold, Y_p_fold,multi_class='ovo', average='macro'),'macro_ovo']))\n",
    "    rac_all=rac_all.append(rac,ignore_index=True)\n",
    "\n",
    "    # N used features in the model\n",
    "    feats= dict(zip(['N_features',  'Group'],[(classifier.coef_ !=0).sum(),  'all']))\n",
    "    feats_all = feats_all.append(feats,ignore_index=True)\n",
    "savePickle(pathClassification+'logisticOrdinalRegression.pkl',{'prfs':prfs_all,'rac':rac_all,'featsN':feats_all})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=loadPickle(pathClassification+'logisticOrdinalRegression.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F score summary for ordinal logistic regression\n",
      "Mean cross validation F score averaged across all phenotypes and standard error\n",
      "macro       0.23  +- 0.03\n",
      "micro       0.35  +- 0.04\n",
      "Mean cross validation F score of individual phenotypes and standard error\n",
      "no_agg      0.65  +- 0.06\n",
      "mhat        0.28  +- 0.08\n",
      "tip         0.27  +- 0.12\n",
      "tag         0.23  +- 0.04\n",
      "lag         0.22  +- 0.03\n",
      "slug        0.16  +- 0.10\n",
      "cul         0.15  +- 0.09\n",
      "FB          0.14  +- 0.10\n",
      "disappear   0.13  +- 0.08\n",
      "stream      0.04  +- 0.04\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary=summary_classification(result['prfs'],'F_score',\"Group\",print_df=False)\n",
    "print('F score summary for ordinal logistic regression')\n",
    "summary_classification_print_sort(summary,statistic='F score',averages=['macro','micro'],groups=order)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The ordinal regression can not directly deal with multiple target features that are ordered. This explains the poor performance compared to the OvR classifier. When triing to convert multi label data into single label multi class data each sample was assigned a single label (with same sample occuring multiple times with different labels). At prediction time each such repeated sample originating form the same original sample got the same predicted label with highest probability. Therefore all but one of the repeated samples necesarily got the wrong label. An option to mitigate this would be to use original samples in predictions (non repeated), assigning them all classes with p > X. However, it is not clear how to select X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
